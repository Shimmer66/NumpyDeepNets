{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T10:10:36.425914Z",
     "start_time": "2024-05-26T10:10:34.687239Z"
    }
   },
   "id": "8396c7407557ba33",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 激活函数及其导数\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "# 多分类\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# 均方误差损失函数及其导数\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "def mean_squared_error_derivative(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_true.size\n",
    "\n",
    "\n",
    "# 损失函数及其导数\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred + 1e-15), axis=1))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cross_entropy_loss_derivative(y_true, y_pred):\n",
    "    return y_pred - y_true\n",
    "\n",
    "\n",
    "# MLP类定义\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # 初始化权重和偏置\n",
    "        self.W1 = np.random.randn(input_size, hidden_size1) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size1))\n",
    "        self.W2 = np.random.randn(hidden_size1, hidden_size2) * 0.01\n",
    "        self.b2 = np.zeros((1, hidden_size2))\n",
    "        self.W3 = np.random.randn(hidden_size2, output_size) * 0.01\n",
    "        self.b3 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 前向传播\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = relu(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W3) + self.b3\n",
    "        self.a3 = softmax(self.z3)  # 输出层使用Softmax激活函数\n",
    "        return self.a3\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        # 反向传播\n",
    "        m = X.shape[0]  # 使用输入样本数\n",
    "        # print(f\"m:{m}\")\n",
    "\n",
    "        # 计算输出层的梯度\n",
    "        d_loss_a3 = cross_entropy_loss_derivative(y, self.a3)\n",
    "\n",
    "        # 计算第三层的梯度\n",
    "        d_loss_W3 = np.dot(self.a2.T, d_loss_a3) / m\n",
    "        d_loss_b3 = np.sum(d_loss_a3, axis=0, keepdims=True) / m\n",
    "\n",
    "        # 计算第二层的梯度\n",
    "        d_loss_a2 = np.dot(d_loss_a3, self.W3.T)\n",
    "        d_loss_z2 = d_loss_a2 * relu_derivative(self.z2)\n",
    "        d_loss_W2 = np.dot(self.a1.T, d_loss_z2) / m\n",
    "        d_loss_b2 = np.sum(d_loss_z2, axis=0, keepdims=True) / m\n",
    "\n",
    "        # 计算第一层的梯度\n",
    "        d_loss_a1 = np.dot(d_loss_z2, self.W2.T)\n",
    "        d_loss_z1 = d_loss_a1 * relu_derivative(self.z1)\n",
    "        d_loss_W1 = np.dot(X.T, d_loss_z1) / m\n",
    "        d_loss_b1 = np.sum(d_loss_z1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # 更新权重和偏置\n",
    "        self.W3 -= learning_rate * d_loss_W3\n",
    "        self.b3 -= learning_rate * d_loss_b3\n",
    "        self.W2 -= learning_rate * d_loss_W2\n",
    "        self.b2 -= learning_rate * d_loss_b2\n",
    "        self.W1 -= learning_rate * d_loss_W1\n",
    "        self.b1 -= learning_rate * d_loss_b1\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            loss = cross_entropy_loss(y, output)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_predicted=self.forward(X)\n",
    "        predictions = np.argmax(y_predicted, axis=1)\n",
    "        labels = np.argmax(y, axis=1)\n",
    "        return np.mean(predictions == labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def save_weights(self, file_path):\n",
    "        weights = {\n",
    "            'W1': self.W1,\n",
    "            'b1': self.b1,\n",
    "            'W2': self.W2,\n",
    "            'b2': self.b2,\n",
    "            'W3': self.W3,\n",
    "            'b3': self.b3\n",
    "        }\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pickle.dump(weights, file)\n",
    "\n",
    "    def load_weights(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            weights = pickle.load(file)\n",
    "            self.W1 = weights['W1']\n",
    "            self.b1 = weights['b1']\n",
    "            self.W2 = weights['W2']\n",
    "            self.b2 = weights['b2']\n",
    "            self.W3 = weights['W3']\n",
    "            self.b3 = weights['b3']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T10:10:36.458904Z",
     "start_time": "2024-05-26T10:10:36.428893Z"
    }
   },
   "id": "ddb587b476d2838d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_california_data(datafile='./data/housing.csv'):\n",
    "    def load_and_inspect_data(datafile):\n",
    "        data = pd.read_csv(datafile, sep=',')\n",
    "        print(\"原始数据形状:\", data.shape)\n",
    "        print(\"原始数据头部:\\n\", data.head(), \"\\n\")\n",
    "        return data\n",
    "\n",
    "    def clean_data(data):\n",
    "        data = data.drop([\"longitude\", \"ocean_proximity\"], axis=1)\n",
    "        print(\"数据信息:\\n\", data.info(), \"\\n\")\n",
    "        print(\"数据描述统计量:\\n\", data.describe(), \"\\n\")\n",
    "        null_counts = data.isnull().sum()\n",
    "        print(\"缺失值统计:\\n\", null_counts, \"\\n\")\n",
    "        data = data.dropna()\n",
    "        print(f\"删除缺失值后的数据形状: {data.shape}\\n\")\n",
    "        return data\n",
    "\n",
    "    def preprocess_features_and_labels(data):\n",
    "        X = data.drop([\"median_house_value\"], axis=1).values\n",
    "        y = data[\"median_house_value\"].values\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        return X, y\n",
    "\n",
    "    def split_data(X, y):\n",
    "        train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"训练集特征形状:\", train_X.shape)\n",
    "        print(\"测试集特征形状:\", test_X.shape)\n",
    "        print(\"训练集标签形状:\", train_y.shape)\n",
    "        print(\"测试集标签形状:\", test_y.shape)\n",
    "        return train_X, test_X, train_y, test_y\n",
    "\n",
    "    data = load_and_inspect_data(datafile)\n",
    "    data = clean_data(data)\n",
    "    X, y = preprocess_features_and_labels(data)\n",
    "    train_X, test_X, train_y, test_y = split_data(X, y)\n",
    "\n",
    "    return train_X, test_X, train_y, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T10:10:37.431788Z",
     "start_time": "2024-05-26T10:10:36.460832Z"
    }
   },
   "id": "e55a30ad94c995e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据形状: (20640, 10)\n",
      "原始数据头部:\n",
      "    longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   latitude            20640 non-null  float64\n",
      " 1   housing_median_age  20640 non-null  float64\n",
      " 2   total_rooms         20640 non-null  float64\n",
      " 3   total_bedrooms      20433 non-null  float64\n",
      " 4   population          20640 non-null  float64\n",
      " 5   households          20640 non-null  float64\n",
      " 6   median_income       20640 non-null  float64\n",
      " 7   median_house_value  20640 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n",
      "数据信息:\n",
      " None \n",
      "\n",
      "数据描述统计量:\n",
      "            latitude  housing_median_age   total_rooms  total_bedrooms  \\\n",
      "count  20640.000000        20640.000000  20640.000000    20433.000000   \n",
      "mean      35.631861           28.639486   2635.763081      537.870553   \n",
      "std        2.135952           12.585558   2181.615252      421.385070   \n",
      "min       32.540000            1.000000      2.000000        1.000000   \n",
      "25%       33.930000           18.000000   1447.750000      296.000000   \n",
      "50%       34.260000           29.000000   2127.000000      435.000000   \n",
      "75%       37.710000           37.000000   3148.000000      647.000000   \n",
      "max       41.950000           52.000000  39320.000000     6445.000000   \n",
      "\n",
      "         population    households  median_income  median_house_value  \n",
      "count  20640.000000  20640.000000   20640.000000        20640.000000  \n",
      "mean    1425.476744    499.539680       3.870671       206855.816909  \n",
      "std     1132.462122    382.329753       1.899822       115395.615874  \n",
      "min        3.000000      1.000000       0.499900        14999.000000  \n",
      "25%      787.000000    280.000000       2.563400       119600.000000  \n",
      "50%     1166.000000    409.000000       3.534800       179700.000000  \n",
      "75%     1725.000000    605.000000       4.743250       264725.000000  \n",
      "max    35682.000000   6082.000000      15.000100       500001.000000   \n",
      "\n",
      "缺失值统计:\n",
      " latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "dtype: int64 \n",
      "\n",
      "删除缺失值后的数据形状: (20433, 8)\n",
      "\n",
      "训练集特征形状: (16346, 7)\n",
      "测试集特征形状: (4087, 7)\n",
      "训练集标签形状: (16346,)\n",
      "测试集标签形状: (4087,)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = load_california_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T10:10:37.529721Z",
     "start_time": "2024-05-26T10:10:37.433781Z"
    }
   },
   "id": "3d9cd80324e55dd6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3025509537665756\n",
      "Epoch 100, Loss: 2.2966796033832386\n",
      "Epoch 200, Loss: 1.1496113881550216\n",
      "Epoch 300, Loss: 0.6376834921761966\n",
      "Epoch 400, Loss: 0.4369163678380998\n",
      "Epoch 500, Loss: 0.3542330706425764\n",
      "Epoch 600, Loss: 0.29741057084043016\n",
      "Epoch 700, Loss: 0.2547212442832033\n",
      "Epoch 800, Loss: 0.22011188482054053\n",
      "Epoch 900, Loss: 0.19218529935925044\n",
      "Train Accuracy: 95.15%\n"
     ]
    }
   ],
   "source": [
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 创建MLP模型\n",
    "    mlp = MLP(input_size=7, hidden_size1=64, hidden_size2=32, output_size=1)\n",
    "    #\n",
    "    # # 训练MLP模型\n",
    "    mlp.train(train_X, train_y, epochs=1000, learning_rate=0.2)\n",
    "    #\n",
    "    # 保存训练后的权重\n",
    "    mlp.save_weights('./data/mlp_weights.pkl')\n",
    "    # 评估模型\n",
    "    train_accuracy = mlp.accuracy(train_X,train_y)\n",
    "\n",
    "    print(f'Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T06:22:47.632018Z",
     "start_time": "2024-05-19T06:06:15.729715Z"
    }
   },
   "id": "initial_id",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_california_data(datafile):\n",
    "    \"\"\"\n",
    "    加载并预处理加州房价数据集。\n",
    "\n",
    "    参数:\n",
    "    datafile (str): 包含数据集的CSV文件的路径。\n",
    "\n",
    "    返回:\n",
    "    tuple: 标准化后的特征矩阵X和目标向量y。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 读取CSV文件\n",
    "        data = pd.read_csv(datafile, sep=',')\n",
    "\n",
    "        # 删除无关列\n",
    "        data = data.drop([\"longitude\", \"ocean_proximity\"], axis=1)\n",
    "\n",
    "        # 填充缺失值\n",
    "        data[\"total_bedrooms\"].fillna(data[\"total_bedrooms\"].median(), inplace=True)\n",
    "\n",
    "        # 分离特征和目标\n",
    "        X = data.drop([\"median_house_value\"], axis=1).values\n",
    "        y = data[\"median_house_value\"].values\n",
    "\n",
    "        # 标准化特征\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {datafile} 时发生错误: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:41:19.637Z",
     "start_time": "2024-05-31T08:41:17.860871Z"
    }
   },
   "id": "532fab2647fdbda8",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datafile = \"./data/housing.csv\"\n",
    "X, y = load_california_data(datafile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:42:29.003873Z",
     "start_time": "2024-05-31T08:42:28.968062Z"
    }
   },
   "id": "aeb894bd191dc95a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.05254828,  0.98214266, -0.8048191 , ..., -0.9744286 ,\n        -0.97703285,  2.34476576],\n       [ 1.04318455, -0.60701891,  2.0458901 , ...,  0.86143887,\n         1.66996103,  2.33223796],\n       [ 1.03850269,  1.85618152, -0.53574589, ..., -0.82077735,\n        -0.84363692,  1.7826994 ],\n       ...,\n       [ 1.77823747, -0.92485123, -0.17499526, ..., -0.3695372 ,\n        -0.17404163, -1.14259331],\n       [ 1.77823747, -0.84539315, -0.35559977, ..., -0.60442933,\n        -0.39375258, -1.05458292],\n       [ 1.75014627, -1.00430931,  0.06840827, ..., -0.03397701,\n         0.07967221, -0.78012947]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:43:13.431065Z",
     "start_time": "2024-05-31T08:43:13.424063Z"
    }
   },
   "id": "99ee0ba9f08cbd12",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([452600., 358500., 352100., ...,  92300.,  84700.,  89400.])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:43:20.571680Z",
     "start_time": "2024-05-31T08:43:20.566681Z"
    }
   },
   "id": "5d87c002faada827",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0a3e1416ea84a97"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
